# -*- coding: utf-8 -*-
"""PPI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17M98spnP9FKChCXkWtGDdglKoMKhTFWA

# **PPI Analysis**
"""

# Obtained the dataset from: 'https://www.kaggle.com/datasets/spandansureja/ppi-dataset/data'
# The aim of this exercise is to improve my skills.
# Credit goes to SPANDAN SUREJA since I chose to perform the same analysis he suggested.

"""**Loading the Data**"""

import pandas as pd

# Load each of te csv files
ppi = pd.read_csv('positive_protein_sequences.csv')
non_ppi = pd.read_csv('negative_protein_sequences.csv')

"""**Preprocessing**"""

# Merge and save
ppi["PPI"]=1
non_ppi["PPI"]=0
df = pd.concat([ppi, non_ppi], axis=0)

df

df.reset_index(drop=True, inplace=True)

# List of the different aminoacids
all_aa = {'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I',
          'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V'}

def count_non_standard(sequence):
    non_standard = [aa for aa in sequence if aa not in all_aa]

    if non_standard:
        print(set(non_standard))  # Print unique non-standard amino acids
    return bool(non_standard)  # Return True if there are non-standard amino acids

count_non_standard1 = sum(count_non_standard(seq) for seq in df['protein_sequences_1']) # Counts the non standard amino acids in sequence 1
print("Number of sequences with non-standard amino acids:", count_non_standard1)

count_non_standard2 = sum(count_non_standard(seq) for seq in df['protein_sequences_2'])  # Counts the non standard amino acids in sequence 2
print("Number of sequences with non-standard amino acids:", count_non_standard2)

"""**Adding Peptide Features**"""

!pip install biopython

# Add length
df['protein_sequences_1_length'] = df['protein_sequences_1'].str.len()
df['protein_sequences_2_length'] = df['protein_sequences_2'].str.len()

df

from Bio.SeqUtils.ProtParam import ProteinAnalysis

protein_seq = "CXOURJMN" # Random sequence
X = ProteinAnalysis(protein_seq)
print(X.count_amino_acids())

def aa_comp(protein_seq):
    amino_acid_composition = {}
    # The protein list is from https://github.com/biopython/biopython/blob/master/Bio/Data/IUPACData.py
    amino_acids = list("ACDEFGHIKLMNPQRSTVWYU")

    for aa in amino_acids:
        amino_acid_composition[aa] = round(float(protein_seq.count(aa)) / len(protein_seq) * 100, 3)

    return amino_acid_composition

# Call the function
x = aa_comp(protein_seq)

# Print the result
print('Amino acid composition:', x)

# Apply the function to sequence 1
aa_df = df['protein_sequences_1'].apply(aa_comp)

# Add the prefix
aa_df = aa_df.apply(pd.Series).add_prefix('p1_')

# Concatenate
df = pd.concat([df, aa_df], axis=1)

# Repeat for sequence 2
aa_df = df['protein_sequences_2'].apply(aa_comp)
aa_df = aa_df.apply(pd.Series).add_prefix('p2_')
df = pd.concat([df, aa_df], axis=1)

df

from Bio.SeqUtils.ProtParam import ProteinAnalysis

# Aromaticity
protein_seq = "YMNOS"

X = ProteinAnalysis(protein_seq)

print(X.molecular_weight())
print(X.aromaticity())
print(X.isoelectric_point())
print(X.secondary_structure_fraction())

# Define a function that returns all of the protein's properties

def get_protein_properties(protein_seq):
  analysis = ProteinAnalysis(protein_seq)
  molecular_weight = analysis.molecular_weight()
  aromaticity = analysis.aromaticity()
  isoelectric_point = analysis.isoelectric_point()
  secondary_structure_fraction = analysis.secondary_structure_fraction()

  return {
      'Molecular_Weight': molecular_weight,
      'Aromaticity': aromaticity,
      'Isoelectric_Point': isoelectric_point,
      'Secondary_Structure_Fraction': secondary_structure_fraction,
      'Helix': secondary_structure_fraction[0],
      'Turn': secondary_structure_fraction[1],
      'Sheet': secondary_structure_fraction[2]
  }

properties_df =df['protein_sequences_1'].apply(get_protein_properties)

properties_df = properties_df.apply(pd.Series)

df = pd.concat([df, properties_df], axis=1)

properties_df =df['protein_sequences_2'].apply(get_protein_properties)

properties_df = properties_df.apply(pd.Series)

df = pd.concat([df, properties_df], axis=1)

df

cols = df.columns.tolist()
cols = [col for col in cols if col not in ['protein_sequences_1', 'protein_sequences_2', 'PPI']]

!pip install plotly

# Once I arrived to this part I had issues plotting due to the data not being 1-D amongst others.
# Here, I attempt to look at the data again prior to plotting.
print("DataFrame shape:", df.shape)
print("\nColumn names:")
print(df.columns)

print("\nDetailed column information:")
for col in df.columns:
    print(f"\nColumn: {col}")
    print(f"Type: {type(df[col])}")
    print(f"Shape: {df[col].shape}")
    if isinstance(df[col], pd.DataFrame):
        print(f"Nested columns: {df[col].columns}")
    print("First few values:")
    print(df[col].head())
    print("-" * 50)

# Flatten the data so as to plot
def flatten_nested_df(df):
    flattened_data = {}
    for col in df.columns:
        if isinstance(df[col], pd.DataFrame):
            # Take only the first column of the nested DataFrame
            flattened_data[col] = df[col].iloc[:, 0]
        else:
            flattened_data[col] = df[col]

    return pd.DataFrame(flattened_data)

# Flatten the DataFrame
df_flat = flatten_nested_df(df)

print("Flattened DataFrame shape:", df_flat.shape)
print("\nFlattened DataFrame columns:")
print(df_flat.columns)

# Split the 'Secondary_Structure_Fraction' column if it contains tuples
if 'Secondary_Structure_Fraction' in df_flat.columns and isinstance(df_flat['Secondary_Structure_Fraction'].iloc[0], tuple):
    df_flat[['SSF_1', 'SSF_2', 'SSF_3']] = df_flat['Secondary_Structure_Fraction'].apply(pd.Series)
    df_flat = df_flat.drop('Secondary_Structure_Fraction', axis=1)

# Update the cols list
cols = [col for col in df_flat.columns if col not in ['protein_sequences_1', 'protein_sequences_2', 'PPI']]

print("Updated DataFrame columns:")
print(df_flat.columns)

import plotly.express as px

for col in cols:
    try:
        fig = px.box(df_flat, x='PPI', y=col, title=f"Comparison of {col} Between PPI Occurrence")
        fig.show()
    except Exception as e:
        print(f"Error plotting {col}: {str(e)}")

import numpy as np

# Calculate the correlation matrix
numeric_cols = df_flat[cols].select_dtypes(include=[np.number]).columns
corr_matrix = df_flat[numeric_cols].corr()

print("Correlation matrix shape:", corr_matrix.shape)
print(corr_matrix)

"""# **Models**

**Splitting**
"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
# Assuming 'X' contains your feature matrix and 'y' contains the target labels
X = df_flat[numeric_cols].values
y = df_flat['PPI'].values

# Split data into train, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.6, random_state=42)

"""**Random Forest Classifier**"""

from sklearn.ensemble import RandomForestClassifier

# Create the RFC model
rfc = RandomForestClassifier(n_estimators = 200, random_state = 42)
rfc.fit(X_train, y_train)

# Validation
y_val_pred = rfc.predict(X_val)
val_accuracy = accuracy_score(y_val, y_val_pred)
print("Validation Accuracy:", val_accuracy)

# Testing
y_test_pred = rfc.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)
print("Testing Accuracy:", test_accuracy)

from sklearn.metrics import confusion_matrix
y_pred2 = rfc.predict(X)
# Assuming 'y_pred' contains predicted labels and 'y_actual' contains actual labels
cm2 = confusion_matrix(y, y_pred2)

cm2

plt.figure(figsize=(8, 6))
sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues', xticklabels=rfc.classes_, yticklabels=rfc.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

imp = rfc.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': cols, 'rf': imp})
feature_importance_df = feature_importance_df.sort_values(by='rf', ascending=False)
feature_importance_df
